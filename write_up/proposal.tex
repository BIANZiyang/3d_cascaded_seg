\documentclass[12pt]{article}

\usepackage{fancyhdr,amsmath}

\usepackage{graphicx}
\usepackage[CJKbookmarks=true,colorlinks,linkcolor=black,anchorcolor=blue,citecolor=blue, urlcolor = blue]{hyperref}
\usepackage{ctex}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{stmaryrd}
\usepackage{cases}
\usepackage{bbm}
\usepackage{upgreek}
\usepackage{bm}

\usepackage{xspace}
\usepackage{comment}
\usepackage{multirow}

\usepackage{sidecap}

\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\makeatletter
\newcommand{\bfgreek}[1]{\bm{\@nameuse{#1}}}
\makeatother


\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}

\usepackage{url}
\usepackage{algorithmic}
\usepackage{appendix}
\newcounter{algorithmbis}
\setcounter{algorithmbis}{0}
\renewcommand{\thealgorithmbis}{\thesection.\arabic{algorithmbis}}
\def\algorithmbis{\@ifnextchar[{\@algorithmbisa}{\@algorithmbisb}}
\def\@algorithmbisa[#1]{%
  \refstepcounter{algorithmbis}
  \trivlist
  \leftmargin\z@
  \itemindent\z@
  \labelsep\z@
  \item[\parbox{\textwidth}{%
    \hrule
    \hrule
    \noindent\strut\textbf{Algorithm \thealgorithmbis} #1
    \hrule
  }]\hfil\vskip0em%
}
\def\@algorithmbisb{\@algorithmbisa[]}
\def\endalgorithmbis{\hfil\vskip-1em\hrule\endtrivlist}
\makeatother
\begin{document}

初步思路：
3D mesh$\rightarrow$ mesh decomposition为大量super-patch$\rightarrow$ 两两merge形成 hierarchical segmentation

\section{super-patch}
对应2D image的superpixel，3D mesh decomposition的算法有很多，但是能够得到源代码的工作几乎没有。
不过，受到近年来比较受欢迎的SLIC superpixel算法\cite{achanta2010slic}的启发，根据\cite{shlafman2003metamorphosis}的工作，
我们提出一个利用K-means的super-patch算法。对于任意一个triangular mesh model，标准化后，我们将其看作一个graphical model, 用G(V,E)：每个节点$V_i$代表
一个face，相互连接的节点表示相互相邻的面，每一条Edge上定义$Distance(V_i, V_j)$为两个face的``距离''：
$$Distance(V_i, V_j) =a\cdot (1-cos^2(\alpha))+b\cdot Phy\_Dist(V_i, V_j)$$
其中$\alpha$是两个面之间的dihedral angle，$Phy\_Dist(V_i, V_j)$是两个面的重心到相邻edge的中点的距离之和。权重$a,b$保证了这个距离在[0,1]之间。
具体的选取由下段描述的training决定。

\subsection{Training}
受Berkeley的segementation dataset\cite{MartinFTM01}的影响，2009年Princeton发布了3D segmentation的benchmark\cite{Chen:2009:ABF}，400个model中每个模型都由若干位志愿者做出了分割，做为ground truth。任取200个模型作为training set，剩下的其中100个模型作为test set，另外100个模型作为validation set，把training set中的每一对相邻的face提取出来，计算$((1-cos^2(\alpha)), Phy_Dist(V_i, V_j))$，定义$Distance_{groundtruth}$为$V_i, V_j$同属不同segment中的概率（在每个模型中13 个ground truth中label不同的概率）。接下来就可以通过一个简单的logistic regression 来将a, b确定。

\subsection{K-means clustering}
当distance被定义好后，对于任意模型，每一对相邻的$(V_i, V_j)$之间的distance就可以算出来了。再定义任意两个不相邻的face 之间的距离为
$$Distance(V_i, V_j)= min_{V_3 \neq V_1,V_2}(Distance(V_1, V_3)+Distance(V_3,V_2))$$
在计算的时候可以运用寻找最短路径的Shortest Path Faster Algorithm(SPFA)算法，接下来就可以开始做clustering了。由于我们定义的距离函数很简单，而且对初始的over-segmentation的精度没有特别严格的要求（仅仅是想让每个3d 模型中的patch个数相同），所以我们取k为一个比较大的值。(k=2000)

\begin{algorithmic}[1]
\STATE Initialize Cluster centers $C_k$ by randomly choosing k faces
\STATE set label $l(i) = -1$ for each face $i$
\STATE set distance $d(i) = \infty$ for each face $i$
\STATE set residual error $E= \infty$
\WHILE{$E$ won't change}
    \FOR{Each cluster center $C_k$}
        \FOR{each face $i$}
            \STATE compute $D=Distance(C_k, i)$
            \IF{$D<d(i)$}
                \STATE set $d(i)=D$
                \STATE set $l(i)=k$
            \ENDIF
        \ENDFOR
    \ENDFOR
    \STATE Compute new cluster centers(move to the closest face centers)
    \STATE Compute residual error E(distance between previous centers and recomputed centers)
\ENDWHILE
\end{algorithmic}

super patch的代码（包括training）在3d\_cascaded\_seg/super\_patch中。

\section{Super-Patch Merging}

\subsection{Boundary Recall Measurement}
受\cite{achanta2010slic}中二维图片measurement的启发，我们定义三维mesh的boundary recall如下：
\begin{equation}
 BR_G(S) = \frac{\sum_{p \in \partial G}\mathbbm{1}(\min_{q \in \partial S}distance(p, q)<\epsilon)}{\partial G}
\end{equation}
其中G为ground truth segmentation, S 为machine segmentation, $\partial$表示分割的边缘(boundary)。对于3D mesh，定义两两vertex之间的edge作为boundary，这样
一个segmentation的边缘就由很多线段组成。将每条线段类比为2D中的pixel，2D中两个pixel之间的距离可以直接计算，而计算两个线段的距离的时候，我们利用\cite{LineDist}中的方法（helper/DistBetween2LineSegment\_mex.mex）

这个measurement数值越大说明真实的边缘检测出来的比例越多。

$\bigstar$我写的计算这个measurement的代码复杂度是$O(\partial G*\partial S)$，因此计算速度极慢，不知道能不能写一个更快的算法，因为速度原因在cascade training的时候也收到了很大的影响。

\subsection{other measurements}
其他的measurement包括rand index(有代码), Cut Discrepancy, Hamming Distance等等。其中rand index是很多3D segmentation paper中都使用的度量。这个度量的计算写出的代码运行可以很快(randindex.cpp)。
\subsection{Cascaded algorithm for super-patch agglomeration}
这部分的思路主要借鉴\cite{cascade_CVPR}。将每个super-patch对应于文中的super-pixel, 其余的思路是类似的。$\bigstar$ 所有算法和\cite{cascade_CVPR}中框架一样。

对于一个3D Model $I_i$, 我们将其分为$k_i$个super-patch$R_i = \{R_{i,1}, ..., R_{i,k_i}\}$，再令$N(R_i)$为所有的相邻区域。每一个区域对$(p,q)\in N(R_i)$ 都由一个表示特征的向量$\phi_{p,q}(I_i, R_i)$组成。具体使用的特征在section \ref{featureSelection}中会介绍。

我们同时也有ground truth的数据，它们将作为训练样本。这些真实的分割数据是以带标签的3D模型表示的，由于我们不假定任何类别信息，所以我们仅仅需要得到的信息是：任意一对像素是否属于同一区域。

利用模型$I$的真实分割的数据，我们可以给$N(R_i)$中的区域对加上标签：任给一个真实分割图$G_i$，我们将$R_{i,p}$标定为$G_i$中与它重合最大的区域的标签。接下来，如果$R_{i,p}$与$R_{i,q}$的标签是相同的，则定义$y_{pq}^i = 1$，否则$y_{pq}^i = 0$。如果对于一张图有很多的真实分割，则定义$y_{pq}^i$为针对所有真实分割定义标签的平均。这样$y_{pq}^i$的值就在0和1之间，度量了人们认为$R_{i,p}$和$R_{i,q}$相同的概率，同时也反映了区域之间边缘的强度。

将训练样本$I_1, ...,  I_N$中区域对的特征和他们的标签放在一起，我们得到$\{<\phi_i, y_i>\}$，这样就是一个预测问题：给定一个区域$I$和初始分割$R$，估计相邻区域聚合的条件后验概率为$Pg(p,q;I,R) \triangleq = P(y_{pq}=1 | \phi_{pq}(I, R))$。如果$Pg(p,q;I,R)>\frac{1}{2}$，则我们必须聚合$R_p$和$R_q$，并且将它们之间的边缘去掉，否则我们将保留边缘。

虽然我们可以直接一次性地预测所有的区域对，但我们寻求一个比较简单的贪婪聚合算法。在每一个循环中，我们将拥有最大的$Pg$的区域对聚合，直到没有任何区域对$Pg>\frac{1}{2}$为止。由于我们是从一个比较精确的分割将其聚合为一个比较粗糙的分割，我们会保证存在一个比较有意义的分割$R'$，需要注意的是，在聚合之前的更新操作只会影响相邻区域，而不会影响其他区域

\subsubsection{training}
我们用一个logistic回归模型来表示$Pg$
$$Pg(p,q;I,R) = 1/(1+exp{-w^T\phi_{pq}(I,R)})$$

这个模型一般来说是用最小化log-loss方法进行训练的，然而，在这里简单地利用log-loss进行训练会失败，因为它会对称地惩罚两种错误:过分和低估 Pg的大小。给定一个典型的图像$I$，一般来说它有1000个superpixels，仅仅有一小部分$N(R)$中的区域对为true negative，因为大部分相邻的superpixels应当被聚合在一起。

我们的解决办法同样是修改损失方程：false positive（错误地聚合的区域）的cost前面乘一个系数$\alpha$，进一步地，我们还在损失方程前面乘上边缘的长度$L_i$。这个尺度变换反映了``擦除''长的边缘比短的边缘惩罚的多：
\begin{equation}
  \label{eq:loss}
  \mathbf{w}^\ast(\alpha)\,=\,\argmin_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^n\Bigl[y_i
\log Pg(\bfgreek{phi}_i;\mathbf{w})+
\alpha(1-y_i)\log(1-Pg(\bfgreek{phi}_i;\mathbf{w}))
\Bigr]
\end{equation}
\eqref{eq:loss}中的带权损失函数是凸的，因此可以像通常的logistic回归模型那样优化。

我们对于$\alpha$的选择是由下面的想法产生的：我们想要尽可能地保持最初分割的Boundary Recall，同时还要尽可能多地聚合区域。其中Boundary Recall $REC(R, G)$定义为每张图中真实分割$G$中的边缘里被检测出的比例的平均。

一般地，Recall的值相对于$\alpha$是递增的。假定最初的分割中的recall 是$r$，则我们希望找到一个$\alpha$的值，它尽可能地小，并且使得recall 的值不会降低到$r-\rho$之下，其中$\rho$为一个很小的数值。这样就启发我们寻找一个优化$\alpha$的有效算法：取一个0 到一个很大的数的区间包含$\alpha$，接下来使用二分查找方法。我们利用两个图像数据集的子集：$I_{train}$来选取$\alpha$，而$I_{tune}$用刚刚得到的$\alpha$来评价Recall 的值。
\subsubsection{cascaded merging}
当模型用带权的损失函数\eqref{eq:loss}进行训练的时候，聚合的过程一般来说会很早就停止了，这样就会留下很多没有聚合的区域$s$。 原因在于我们的模型在聚合的时候十分的``小心''，同时由于新聚合的区域中的特征的分布和之前训练中用到的特征不同，很小的区域中无效的特征可能会在更大的区域中变得有效。这引导我们产生一个简单的想法：对聚合的区域重新提取特征，重新在更大的区域上进行训练。这样的第二个模型会聚合更多的分割区域，不过它仍然会停止。我们则会继续训练第三个模型，以此类推。

训练这个级联模型的过程和其他级联模型的训练方法是类似的，最大的区别在于，我们使用的是非对称的损失函数，而不是手动地调试参数。这样我们就可以训练一个更深的级联。

总而言之：整个算法从super-patch开始，通过一系列阶段进行增殖。在每个阶段中，一些区域被阶段中学习到的模型进行聚合，接下来的阶段用粗糙一些的分割作为输入。当聚合过程停止的时候，我们可以向后遍历，并记录每一步的分割过程。这样，我们就可以用两种方法控制分割的尺度：或者输入想要得到的分割个数，或者输入分割阶段的次数。

$\bigstar$ 这一部分由于要依赖boundary recall的计算($\alpha$的选取过程详见\cite{cascade_CVPR})，而我写的代码实现起来十分慢，所以$\alpha$的选择我也是手工选取的，这一部分是目前主要的瓶颈。

\subsubsection{features between neighboring superpixels}
\label{featureSelection}
这里所说的features都是定义在相邻两个patch $R_{i,q}$上的。
\begin{itemize}
  \item Bounding Box

  先计算每个patch $i$的bounding box $b_i$, 在$R_{i,q}$中，定义$b_i \cap b_q$为两个box的相交部分$c_{iq}$，取$\phi_1(i,q) = \max(\frac{volume(b_i)}{volume(c_{iq})}, \frac{volume(b_q)}{volume(c_{iq})})$，此数值在0，1之间，越接近1 说明二者的包含关系越明显。（可以将bounding box换为凸包，更精确）
  \item Average Norm Vector

  每个mesh i上的法向量为$n_i$，对于每个patch j，定义其平均法向量为所有mesh上的法向量的加权和，权重与每个mesh的面积成正比。

  \item Others: to be continued..
\end{itemize}


\subsection{future work}
\begin{itemize}
  \item 更多的features。
  \item 改进的super-patch算法：如一开始在选取k个点的时候将其均匀分布在模型中
  \item merging前对模型做出初步分析，定义不同的merging模型
\end{itemize}

\appendix
\renewcommand{\appendixpagename}{附录}
\renewcommand{\appendixtocname}{附录}
\appendixpage
\addappheadtotoc
\begin{appendices}
整个project均在F盘上进行操作。
\section{Mesh Segmentation Data}
\begin{itemize}
  \item Princeton's segmentation dataset 存放在F:/MeshsegBenchmark-1.0 中
  \item data/\{train, test, val\}.txt 分别为training, test, validation set
  \item data/off 中存放了所有3维模型，共380个，每10个为一个类别（人，椅子，杯子，等等。。）
  \item data/seg 中存放了各个算法的分割结果，其中Benchmark为ground truth, super\_patch 中存放了super-patch 算法的结果，每个模型2000个分割。
\end{itemize}

这些是所有需要用到的东西。。


\section{codes}
代码保存在F:/github/3d\_cascaded\_seg 其中的readme文件介绍了各个目录的组织情况，全部代码在这里托管
\url{https://github.com/luvegood/3d_cascaded_seg}
请clone这里的代码，台式机里的代码不一定是最新的。
同时，代码还依赖其他的toolbox：geom3d(计算bounding box等等都要用到), toolbox\_graph(3D 图结构的时候利用), minFunc(learning的时候利用)，均在F:/github中。


\end{appendices}

\bibliographystyle{plain}	
\bibliography{3dseg_ref}	
\end{document}
